{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: https://github.com/AdamMeyers/The_Termolator for more.\n",
    "\n",
    "By : \n",
    "\n",
    "Date: 2019/12/9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Termolator is an open source tool for finding terminology in text, first released on July 29, 2015.The Termolator has an English and a Chinese version.\n",
    "The English version includes: \n",
    "\n",
    "(a) a chunker that finds all instances of noun groups in the input files that are likely to be instances of terminology;\n",
    "\n",
    "(b) a state of the art system for generating ranked lists of terms that are more characteristic of a foreground corpus than a background corpus, with precision of approximately 85% for the top 5000 terms, produced from sets of 5000 foreground and background documents. \n",
    "\n",
    "The system uses a combination of statistical and knowledge-based methods.\n",
    "The Chinese Termolator uses a similar system as English for generating ranked lists of terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Downloads\n",
    "\n",
    "[The Termolator](https://nlp.cs.nyu.edu/termolator/)\n",
    "\n",
    "[The English system: Python code and models](https://github.com/AdamMeyers/The_Termolator)\n",
    "\n",
    "The Chinese System: [Binaries and models](https://github.com/ivanhe/termolator/releases/download/Beta1/chinese_term_extraction.zip); [Source code](https://github.com/ivanhe/termolator/).\n",
    "\n",
    "All releases are hosted on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Preparatory work\n",
    "\n",
    "\n",
    "The Termolator takes two sets of documents as input a FOREGROUND set and a BACKGROUND set and finds instances of terminology that are more characteristic of the FOREGROUND than the BACKGROUND. Input files can be either .txt, .html or .xml (the latter only working if it uses HTML style markup to delimit text). UTF-8 encoding (which includes ASCII) is preferred, but ISO-8859-1 will work as well.\n",
    "Instructions for Using program:\n",
    "\n",
    "We will assume that $TERMOLATOR is the path containing the TERMOLATOR program. Setting an environmental variable (called TERMOLATOR) is suggested.\n",
    "\n",
    "To run the main system, the command is as follows (an additional way of running the system will be described in section 10):\n",
    "\n",
    "$TERMOLATOR/run_termolator.sh FOREGROUND BACKGROUND EXTENSION OUTPUT_NAME TRUE-OR-FALSE TRUE-OR-FALSE 30000 5000 PROGRAM-DIRECTORY ADDITIONAL_TOPIC_STRING TRUE-OR-FALSE general_file_name_or_FALSE SHARED_BACKGROUND_FILENAME.pkl MINIMUM_PROBABILITY_OR_FALSE\n",
    "\n",
    "IMPORTANT PATH INFORMATION: If FOREGROUND and BACKGROUND files contain absolute paths, this command will work from anywhere. Otherwise, you should run from the directory containing FOREGROUND and BACKGROUND. We will call this the DATA_DIRECTORY. The files listed in FOREGROUND andBACKGROUND should be paths relative to the DATA_DIRECTORY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Arguments(run_termolator.sh)\n",
    "main file,based on linux\n",
    "\n",
    "\n",
    "\n",
    "The arguments are defined as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Argument 1 (FOREGROUND) = a file listing the documents in the foreground set \n",
    "\n",
    "Argument 2 (BACKGROUND) = a file listing the documents in the background set \n",
    "\n",
    "Argument 3 (EXTENSION) = the extension of input files \n",
    "\n",
    "Argument 4 (OUTPUT_NAME) = name of output file (without extension) \n",
    "\n",
    "Argument 5 (TRUE-OR-FALSE) = True or False (do background files need to be processed?) If False, stored background cache will be loaded (see Argument 13). If True, background information will be stored as a cache file (see Argument 13). \n",
    "\n",
    "Argument 6 (TRUE-OR-FALSE) = True if you want the system to use the relevance score for determining rankings and False otherwise. \n",
    "\n",
    "Argument 7 Maximum Number of Terms Considered (suggested = 30000) \n",
    "\n",
    "Argument 8 Top N -- number of terms you want to keep in the end (suggested 5000-10000) \n",
    "\n",
    "Argument 9 (PROGRAM-DIRECTORY) = the directory where the program is, e.g., $TERMOLATOR if you set this variable. \n",
    "\n",
    "Argument 10 (ADDITIONAL_TOPIC_STRING) = topics connected with a plus sign, e.g., legal+finance. These topics are split by plus signs. The resulting topics correspond to key words in the dictionary_table variable in term_utilities.py. Currently, only the \"legal\" topic is supported. If there are no additional topics, this variable should have \"false\" as a value. If you add the legal topic, a dictionary of legal terms will be downloaded and some specialized rules will be invoked for abbreviations. Other topic specific features may be added in the future. \n",
    "\n",
    "Argument 11 If True, skip preprocessing for Foreground. This comes in useful if you want to run the same Foreground with different backgrounds or if for any reason, you have already preprocessed the foreground file. So usually, this field should just contain \"False\". \n",
    "\n",
    "Argument 12 The name of some of the shared cached data to be used in multiple runs. This is currently being used as a prefix for both webscore files and for lemma dictionary files, e.g., if argument 12 is 'biology', the files will either be created or updated when the program is run. If the value of argument 12 is False, Argument 4 will be used instead, i.e., the files $4_lemma.dict and $4.webscore will be used. Of course a webscore file will only be generated in either case if Argument 6 is True. These cached files make it unnecessary to recalculate webscores for terms that have previously been looked up (saving as much as .75 seconds per term). It also allows different forms of a lemma to be saved over a larger amount of documents (both foreground and background) so that more forms of a lemma are likely to be found. \n",
    "\n",
    "Argument 13 The name of the background cache file associated with Argument 5. If you list False as the background file, a default name (ranking.pkl) will be used (info will be saved to or loaded from this file). It is suggested that you use the .pkl file type, since this is a Python pickle file. \n",
    "\n",
    "Argument 14 Is either a number, the string \"patent\", \"normal\" or \"False\". This argument is used by the language model to cause the program to eliminate some blocks of text. The intension is that \"abnormal\" text such as bibliographies, tables or charts will be ignored because terms extracted from such text are likely to be of low quality. \"False\" causes this component not to do anything. The number should be a negative number between 0 and -2. We are currently using -.2 (negative 2/10) for patent text and -1 for other texts. You can also use the strings \"patent\" and \"normal\" in place of these 2 values. The meaning is that text that the language model classifies as having a probability of less than some number of standard deviations from the mean probability is ignored, whereas higher probability text is processed. Patents tend to have more tables and in-text bibliographies than \"normal\" text and therefore we assume a higher threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Test the program\n",
    "To test the program, we suggest going to one of our 3 test directories and running the command from there. Note that we will shorly be adding a corpus of court decisions, for which the legal topic features are useful. We have not yet tested whether these same features are useful for the patent directory provided here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a) subdirectory: gutenberg-test command: $TERMOLATOR/run_termolator.sh foreground.list background.list .htm knitting True True 30000 5000 $TERMOLATOR False False False gutenberg.pkl -1\n",
    "\n",
    " -- The \"True\" setting in field 6 will make this run take an extra 10 minutes to run about 600 \n",
    "   \t web searches, but the results are more accurate as a result. \n",
    "\n",
    " -- After this run, the background statistics will be stored in gutenberg.pkl. Thus, for a \n",
    "  \t second run, possibly with a different foreground, setting the fifth parameter to False\n",
    "     will make run time be somewhat faster, especially if the sixth parameter is set to False and\n",
    " the websearch score is not used.\n",
    "\n",
    " -- These texts are taken from the English portion of Project Gutenberg, a repository of public \n",
    "  \t domain texts. The FOREGROUND is a set of chapters of \"The Project Gutenberg eBook of Encyclopedia \n",
    " of Needlework\", by Therese De Dillmont. The BACKGROUND is a random selection of documents from the \n",
    " same repository. Thus the resulting terminology list consists of terms in the domain of \"knitting\".\n",
    " For more information of Project Gutenberg, go to: https://www.gutenberg.org/\n",
    "\n",
    " -- The threshold probability is set to -1 standard deviations below the mean probability."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b) subdirectory: OANC-test command: $TERMOLATOR/run_termolator.sh foreground.list background.list .txt biology True False 30000 5000 $TERMOLATOR False False False OANC.pkl -1\n",
    "\n",
    "  -- This run will be faster than the previous run per term generated. If the False in field in field 6 is \n",
    "  \t replaced by True, the system will take an extra 3 hours (about 1 second for each of 10,000 terms),\n",
    "  \t but the results will be better.\n",
    "\n",
    "  -- These texts are taken from the Open American National Corpus (OANC), a project devoted to collecting \n",
    "  \t freely available text for processing by computational linguistics. The FOREGROUND consists of 100 \n",
    " biology related documents and the background consists of 100 random documents.  The resulting terminology \n",
    " are all about biology. For more information about the OANC, go to: http://www.anc.org/data/oanc/\n",
    "\n",
    "  -- The threshold probability is set to -1 standard deviations below the mean probability."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c) subdirectory: patent-test command: $TERMOLATOR/run_termolator.sh foreground.list background.list .XML surgery True False 30000 5000 $TERMOLATOR False False False patent.pk -.2\n",
    "  -- This run should generate about 4700 terms. If False in field 6 is changed to True, it will take an additional \n",
    "  \t 1.5 hours, but  achieve better results.\n",
    "\n",
    "  -- These documents are taken from Google patents. We downloaded files and divided them by the US patent \n",
    "  \t classes encoded in the documents. The foreground is a set of patents in class 606 (see the \n",
    " main_classification field in the XML), which are all about \"Surgery\".  The background is a set of \n",
    " randomly selected patents. The resulting terminology are all in the domain of \"Surgery\".\n",
    "\n",
    "  -- The threshold probability is set to -.2 standard deviations below the mean probability.  Blocks of text are\n",
    "  \t likely to be ignored if they are too different from the norm (based on the OANC text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Choice of foreground and background documents. \n",
    "Different choices will effect the sort of terminology the system will recognize. We recommend between 500 and 5000 small files for both foreground and background or fewer large files. The example documents should give you some idea of what is possible. As the examples show, different numbers of files are possible.\n",
    "\n",
    "We suggest creating directories which have only the input (foreground and background) files in them and then none of the files have any of the following file extensions, as these may be overwritten by the system: .abbr .fact .pos .substring .terms .txt2 .txt3 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.The output produced by the file includes the following, based on the OUTPUT_NAME:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT_NAME.out_term_list --- This is the final output, a list of the top N terms in order of rank, where N = Argument 8 above. Each line consists of the term lemma followed by variants of that lemma, separated by tabs. Consider the following 2 lines from the sample OANC-test biology.out_term_list file:\n",
    "\n",
    " \t\t glucocorticoid receptor glucocorticoid receptors gr\n",
    " \t\t p53 activation activation of p53\n",
    "\n",
    " \t\t As these examples show, the lemma appears first. Then alternative forms \n",
    " \t\t appear including plurals, abbreviations and/or noun phrases with \n",
    " \t\t prepositional phrase right modifiers (we assume that the left modified noun\n",
    " \t\t noun compounds are the lemmas)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OUTPUT_NAME.scored_output --- This is a superset of the previous list, approximately the top 30% of the terms considered by the system or the top K terms, if K is lower than 30%, and where K = Argument 7 above. If Argument 6 is set to True, a .8 seconds-long web search is used to score each of the elements in this list. Thus 30,000 terms will take around 24,000 seconds or just under 7 hours.\n",
    "\n",
    "      --- There are several columns on each line, divided by tabs, as follows: \n",
    " \t\t Column 1 -- the term (just the lemma)\n",
    " \t\t Column 2 -- a rule classification (used to determine if the term is well-formed)\n",
    " \t\t Column 3 -- a value Good, Medium, Neutral (measuring the quality of the term by some set of rules)\n",
    " \t\t Column 4 -- a score between 0 and 1 measuring term quality\n",
    " \t\t Column 5 -- a score between 0 and 1 measuring the term rank\n",
    " \t\t Column 6 -- column 4 X column 5\n",
    " \t\t Column 7 -- the relevance score (if being used)\n",
    " \t\t Column 8 -- column 4 X column 5 X column 7 (if relevance score is used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT_NAME.dict_abbr_to_full -- This is a dictionary taken from the Foreground that maps abbreviations to their full forms, e.g., HTML --> Hypertext Markup Language. It is used for determining if a sequence of words is a valid term.\n",
    "\n",
    "OUTPUT_NAME.dict_full_to_abbr -- This is a dictionary going in the opposite direction, from full forms to terms, e.g., Hypertext Markup Language --> HTML"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OUTPUT_NAME.rejected-terms -- These are terms generated by the system, but rejected either because they are deemed to be ill-formed or they were not ranked sufficiently highly to by the initial steps to be considered (top 30% or top 30K if argument 7 is set to 30,000).\n",
    "\n",
    "      -- There are several columns, similar to OUTPUT_NAME.scored_output\n",
    " \t\t Column 1 -- the term\n",
    " \t\t Column 2 -- \"FILTERED_OUT\" if removed due to a well-formedness rule or \"BEYOND-CUTOFF\", if \n",
    " \t\t \t     removed because the term was ranked lower than 30% or 30K as discussed above.\n",
    " \t\t Column 3 --  a rule classification (used to determine if the term is well-formed)\n",
    " \t\t Column 4 -- a value Good, Medium, Neutral (measuring the quality of the term by some set of rules)\n",
    " \t\t Column 5 -- a score between 0 and 1 measuring term quality\n",
    " \t\t Column 6 -- a score between 0 and 1 measuring the term rank\n",
    " \t\t Column 7 -- column 5 X column 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT_NAME.all_terms -- This is the intermediate list of terms that is generated before 30% or 30K terms are rejected. The scores are based on a distributional component of our system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.For each file processed, the following intermediate files are generated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILE.fact -- this identifies where blocks of text start and end (e.g., paragraphs in html) \n",
    "\n",
    "FILE.txt3 -- the .fact file is pointing to start and end character offsets in this file \n",
    "\n",
    "FILE.pos -- this provides part of speech tags for each token and is used in processing. the start and end numbers point to character offsets in the .txt3 file \n",
    "\n",
    "FILE.terms -- this identifies terms inline, by means of our chunking program. The start and end positions point to character offsets in the .txt3 file. \n",
    "\n",
    "FILE.abbr -- this file identifies relations between abbreviations and full forms in text \n",
    "\n",
    "FILE.subtring -- this file includes both terms from \n",
    "\n",
    "FILE.terms and well-formed substrings of those words used by the distributional system. Note that in earlier versions of Termolator, .tchunk and .tchunk.nps files were used for a similar purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.In addition the following files are created for purposes of speeding up processing in multiple runs:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$13 -- a pickled file storing the background component of the distributional score \n",
    "\n",
    "$12_lemma.dict -- a lemma dictionary, used to generate the non-initial columns in the .out_term_list files \n",
    "\n",
    "$12.webscore -- A file saving webscores for terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.In addition to the \"main\" way of running the system, there are three additional options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Single File as foregound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to run using a single file as foreground. We are currently generating one set of terms using each supreme court decision as foreground and the full set of supreme court decisions as background. In future versions, we will provide an example from this run. To do this, we use the following script with the following arguments:\n",
    "\n",
    "run_termolator_with_1_file_foreground.sh FOREGROUND BACKGROUND EXTENSION OUTPUT_NAME TRUE-OR-FALSE TRUE-OR-FALSE 10000 1000 PROGRAM-DIRECTORY ADDITIONAL_TOPIC_STRING TRUE_OR_FALSE general_file_name_or_FALSE SHARED_BACKGROUND_FILENAME.pkl MINIMUM_PROBABILITY_OR_FALSE\n",
    "\n",
    "This takes all the same arguments as run_termolator.sh, with the following exceptions:\n",
    "\n",
    "Argument 1 (FOREGROUND) is one foreground file, rather than a file containing a list of files. The filetype is left out Arguments 7 and 8 -- lower numbers are recommended for single files. Intially we assume 10000 and 1000, but these numbers are probably too high\n",
    "\n",
    "For the first run, Arguments 5 and 11 should both be True and True if the foreground file is part of the background. If not, then Argument 11 should be False. For subsequent runs Argument 5 should be False (assuming the same background is being used)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Phase 1 Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Suppose you do not want to run the full Termolator system. Suppose you are only interested identifying the technical noun groups that we use as input to the distributional system."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The script run_terms_only.sh takes only five arguments, a subset of the arguments of the full run_termolator.sh script.\n",
    "\n",
    "Argument 1: input files -- a file listing the input txt, or hml (or xml) files\n",
    "Argument 2: file type of input files\n",
    "Argument 3: output_file_name (mainly used for creating dictionary/caching files)\n",
    "Argument 4: directory of termlolator (like run_termolator.sh)\n",
    "Argumeng 5: name of special topic area  (like run_termolator.sh)\n",
    "\n",
    "The program creates some of the same preprocessing files that run_termolator.sh creates, but does\n",
    "not continue to produce a term list. I suspect that the most useful output files are the .terms\n",
    "and .abbr files.  The .terms files are the files listing the technical noun groups found in each\n",
    "of the input files and the .abbr files are the list of abbreviation relations found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. There is a more experimental option."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This has only been partially implemented and not completely tested. Suppose, you want to run Phase 1, but you find that there is some other type of constituent, e.g., named entities, that you can detect by some other means. Furthermore, suppose that Termolator is making errors whereever there are named entities and you would like to eliminate terms that \"conflict\" with these NEs. There is an additional python file that will remove any term from the \"terms\" files. We have not tested this a lot yet, so it is not currently used in any of the shell scripts, so you may have to customize a shell script if you want to incorporate this in a run (either with run_termolator.sh or with run_terms_only.sh).\n",
    "\n",
    "In find_terms.py, there is a function find_inline_terms_for_file_list, which is called by \n",
    "run_find_inline_terms.py (by the shell scripts). That function takes an optional keyword argument\n",
    "\"ne_filter_ending\".  If you set that ending to a file type, e.g., \".ne\" or the like. The program\n",
    "will look for files of that type. Those files will be assumed to include lines of XML with \"start\" \n",
    "and \"end\" values, e.g., \n",
    "<citation id=\"108713_1\" entry_type=\"standard_case\" start=\"1\" end=\"20\" reporter=\"U.S.\" standard_reporter=\"U.S.\" volume=\"410\" page_number=\"113\" year=\"1973\" line=\"2\">410 U.S. 113 (1973)</citation>\n",
    "The values other than start and end do not matter.  The terms collected will not be constrained so\n",
    "they do not include any strings between instances of \"start\" and \"end\" found in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
